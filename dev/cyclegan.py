# -*- coding: utf-8 -*-
"""cyclegan

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/generative/ipynb/cyclegan.ipynb

# CycleGAN

**Author:** [A_K_Nain](https://twitter.com/A_K_Nain)<br>
**Date created:** 2020/08/12<br>
**Last modified:** 2020/08/12<br>
**Description:** Implementation of CycleGAN.

## CycleGAN

CycleGAN is a model that aims to solve the image-to-image translation
problem. The goal of the image-to-image translation problem is to learn the
mapping between an input image and an output image using a training set of
aligned image pairs. However, obtaining paired examples isn't always feasible.
CycleGAN tries to learn this mapping without requiring paired input-output images,
using cycle-consistent adversarial networks.

- [Paper](https://arxiv.org/pdf/1703.10593.pdf)
- [Original implementation](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)

## Setup
"""

import os
from sys import argv
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import tensorflow_addons as tfa
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import ImageDataGenerator


#import tensorflow_datasets as tfds

#tfds.disable_progress_bar()
#autotune = tf.data.experimental.AUTOTUNE

from utils import *

"""## Prepare the dataset

In this example, we will be using the
[horse to zebra](https://www.tensorflow.org/datasets/catalog/cycle_gan#cycle_ganhorse2zebra)
dataset.
"""

# Load the horse-zebra dataset using tensorflow-datasets.
#dataset, _ = tfds.load("cycle_gan/horse2zebra", with_info=True, as_supervised=True)
#train_horses, train_zebras = dataset["trainA"], dataset["trainB"]
#test_horses, test_zebras = dataset["testA"], dataset["testB"]

#print(train_horses)
#print(dir(train_horses))


#def my_convert(fname,dataset):
#    ds_numpy = tfds.as_numpy(dataset) 
#    #print(ds_numpy)
#    xs = []
#    ys = []
#    for x,y in ds_numpy:
#        xs.append(x)
#        ys.append(y)
#    xs = np.array(xs)
#    ys = np.array(ys)
#    print(xs.shape,ys.shape)
#    np.savez(fname,xs=xs,ys=ys)

#my_convert('train_horses',train_horses)
#my_convert('train_zebras',train_zebras)
#my_convert('test_horses',test_horses)
#my_convert('test_zebras',test_zebras)


#horses = np.load('../train_horses.npz')
#zebras = np.load('../train_zebras.npz')
#train_horses = horses['xs'][:1000]
#train_zebras = zebras['xs'][:1000]
#horses = np.load('../test_horses.npz')
#zebras = np.load('../test_zebras.npz')
#test_horses = horses['xs'][:100]
#test_zebras = zebras['xs'][:100]

#train_horses = (train_horses / 127.5) - 1.0
#train_zebras = (train_zebras / 127.5) - 1.0
#test_horses = (test_horses / 127.5) - 1.0
#test_zebras = (test_zebras / 127.5) - 1.0

#print(train_horses.shape,train_zebras.shape)
#exit()

#if tf.test.gpu_device_name(): 
#    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))
#else:
#   print("Please install GPU version of TF")


#dataset = tf.data.Dataset.zip((train_horses, train_zebras))

#for a,b in dataset:
#  print(a[0].numpy())
##  print(b)
#  exit()
#  
#input_img_size = (256, 256, 3)

#  
#tf.data.Dataset.zip((train_horses, train_zebras))
#  
#  
#exit()

# Define the standard image size.
#orig_img_size = (286, 286)
# Size of the random crops to be used during training.




data_set = np.load('dataset_300_300.npy',allow_pickle=True)
data_set.shape = [1]
data_set = data_set[0]
x = []
labels = []
for key in list(data_set):
    x.extend(data_set[key])
    labels.append(len(data_set[key])*[key])
x = np.array(x)
labels = np.array(labels)

#x = data['x']
#labels = data['labels']
print("[INFO] data is loaded...")

int_map,lbl_map = int_label(labels)

vec = [int_map[word] for word in labels]
x = np.array(x)

reg = int(argv[1])
if reg==1:
    x = x[:,100:,20:200] # neck and ear: shape (220, 180)
elif reg==2:
    x = x[:,120:,140:300] # lower face: shape (200, 160)
elif reg==3:
    x = x[:,:-120,100:270] # eye and forehead: shape (200, 170)
elif reg==4:
    x = x[:,20:-120,20:260] # above month: shape (180, 240)


vec = np.array(vec)
y = to_categorical(vec, num_classes=None, dtype='float32')
x = x[:,:,:,None]/x.max()
x = 2*x-1

#describe_labels(y,verbose=1)

# initialize the training data augmentation object
trainAug = ImageDataGenerator(
    rotation_range=5,
    width_shift_range=0.03,
    height_shift_range=0.03,
#   brightness_range=0.01,
#   shear_range=0.0,
    zoom_range=0.03,
#   horizontal_flip=True,
#   vertical_flip=True,
    fill_mode="nearest")
describe_labels(y,verbose=1)
x_us,y_us = balance_aug(x,y,trainAug)
# x_us,y_us = mixup(x,y,alpha=20,beta=1)
describe_labels(y_us,verbose=1)

x_us,y_us = shuffle_data(x_us,y_us)

train_horses = x_us[y_us[:,0].astype(bool)]
train_zebras = x_us[y_us[:,1].astype(bool)]
test_horses = train_horses[:20]
test_zebras = train_zebras[:20]

print(train_horses.shape,train_zebras.shape)
#exit()

#input_img_size = (256, 256, 1)
input_img_size = x.shape[1:]

buffer_size = 256
batch_size = 1


# Get the generators
gen_G = get_resnet_generator(input_img_size,name="generator_G")
gen_F = get_resnet_generator(input_img_size,name="generator_F")

# Get the discriminators
disc_X = get_discriminator(input_img_size,name="discriminator_X")
disc_Y = get_discriminator(input_img_size,name="discriminator_Y")

# Loss function for evaluating adversarial loss
adv_loss_fn = keras.losses.MeanSquaredError()

# Define the loss function for the generators
def generator_loss_fn(fake):
    fake_loss = adv_loss_fn(tf.ones_like(fake), fake)
    return fake_loss


# Define the loss function for the discriminators
def discriminator_loss_fn(real, fake):
    real_loss = adv_loss_fn(tf.ones_like(real), real)
    fake_loss = adv_loss_fn(tf.zeros_like(fake), fake)
    return (real_loss + fake_loss) * 0.5

# Create cycle gan model
cycle_gan_model = CycleGan(
    generator_G=gen_G, generator_F=gen_F, discriminator_X=disc_X, discriminator_Y=disc_Y
)

# Compile the model
cycle_gan_model.compile(
    gen_G_optimizer=keras.optimizers.Adam(learning_rate=5e-5, beta_1=0.5),
    gen_F_optimizer=keras.optimizers.Adam(learning_rate=5e-5, beta_1=0.5),
    disc_X_optimizer=keras.optimizers.Adam(learning_rate=5e-5, beta_1=0.5),
    disc_Y_optimizer=keras.optimizers.Adam(learning_rate=5e-5, beta_1=0.5),
    gen_loss_fn=generator_loss_fn,
    disc_loss_fn=discriminator_loss_fn,
)


#print(K.eval(cycle_gan_model.model.optimizer.lr))

# Callbacks
#plotter = GANMonitor(test_horses)
#checkpoint_filepath = "./model_checkpoints/cyclegan_checkpoints.{epoch:03d}"
#model_checkpoint_callback = keras.callbacks.ModelCheckpoint(
#    filepath=checkpoint_filepath
#)

# Here we will train the model for just one epoch as each epoch takes around
# 7 minutes on a single P100 backed machine.
#cycle_gan_model.fit(
#    tf.data.Dataset.zip((train_horses, train_zebras)),
#    epochs=1,
#    callbacks=[plotter, model_checkpoint_callback],
#)

weight_file = './model_checkpoints/cyclegan_checkpoints.293'
cycle_gan_model.load_weights(weight_file)

cycle_gan_model.fit(
    train_horses, train_zebras,
    batch_size=2,
    epochs=2,
#    callbacks=[plotter, model_checkpoint_callback],
)

cycle_gan_model.saveit('model1/')

cycle_gan_model.loadit('model1/')
"""Test the performance of the model."""

# This model was trained for 90 epochs. We will be loading those weights
# here. Once the weights are loaded, we will take a few samples from the test
# data and check the model's performance.

#!curl -LO https://github.com/AakashKumarNain/CycleGAN_TF2/releases/download/v1.0/saved_checkpoints.zip
#!unzip -qq saved_checkpoints.zip

# Horse to fake zebra
#fake_y = self.gen_G(real_x, training=True)
# Zebra to fake horse -> y2x
#fake_x = self.gen_F(real_y, training=True)

# Load the checkpoints
#weight_file = "./model_checkpoints/cyclegan_checkpoints.293"
#cycle_gan_model.load_weights(weight_file).expect_partial()
print("Weights loaded successfully")

_, ax = plt.subplots(4, 2, figsize=(10, 15))
#for i, img in enumerate(test_horses.take(4)):
for i in range(4):
    img = test_horses[i:i+1]
    prediction = np.array(cycle_gan_model.gen_G(img, training=False)[0])
    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)
    img = (img[0] * 127.5 + 127.5).astype(np.uint8) #.numpy().astype(np.uint8)

    ax[i, 0].imshow(img)
    ax[i, 1].imshow(prediction)
    ax[i, 0].set_title("Input image")
    ax[i, 0].set_title("Input image")
    ax[i, 1].set_title("Translated image")
    ax[i, 0].axis("off")
    ax[i, 1].axis("off")

    prediction = keras.preprocessing.image.array_to_img(prediction)
    prediction.save("predicted_img_{i}.png".format(i=i))
plt.tight_layout()
plt.show()

plt.savefig('fig.jpg',dpi=150)




#{'06-class__2': 0, '04-class__1': 1}
#{0: '06-class__2', 1: '04-class__1'}
#train_horses = x_us[y_us[:,0].astype(bool)]
#train_zebras = x_us[y_us[:,1].astype(bool)]



#for i in range(5):
#    _, ax = plt.subplots(1, 3, figsize=(10, 3))
#    img = test_horses[i:i+1]
#    prediction = np.array(cycle_gan_model.gen_G(img, training=False)[0])
#    #prediction = np.array(cycle_gan_model.gen_G.predict(img))
#    img = img[0,:,:,0]
#    prediction = prediction[:,:,0]
#    print(img.shape,prediction.shape)
#    #prediction = (prediction * 127.5 + 127.5).astype(np.uint8)
#    #img = (img[0] * 127.5 + 127.5).astype(np.uint8) #.numpy().astype(np.uint8)
#    delta = np.abs(img-prediction)

#    ax[0].imshow(img,cmap='gray')
#    ax[1].imshow(prediction,cmap='gray')
#    ax[2].imshow(delta,cmap='jet')
#    ax[0].set_title('06-class__2')
#    ax[1].set_title("Translated image")
#    ax[2].set_title("delta")
#    ax[0].axis("off")
#    ax[1].axis("off")
#    ax[2].axis("off")

#    plt.savefig('{}.jpg'.format(i),dpi=150)
#    plt.close()












